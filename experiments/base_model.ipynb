{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "import warnings\n",
    "import joblib\n",
    "import os \n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dir = '../data/gold/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/maldu/dscience/projects/fraud_detection/experiments/artifacts_local/1', creation_time=1723547342006, experiment_id='1', last_update_time=1723547342006, lifecycle_stage='active', name='fraud_logreg_base_model', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment('fraud_logreg_base_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_npz(os.path.join(load_dir, 'X_train_scaled.npz'))\n",
    "X_test = load_npz(os.path.join(load_dir, 'X_test_scaled.npz'))\n",
    "\n",
    "y_train = joblib.load(os.path.join(load_dir, 'y_train.pkl'))\n",
    "y_test = joblib.load(os.path.join(load_dir, 'y_test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9983\n",
      "Test Accuracy: 0.9979\n",
      "Test Accuracy (using score method): 0.9979\n",
      "Confusion Matrix saved and logged.\n",
      "0 - precision: 0.9980\n",
      "0 - recall: 0.9999\n",
      "1 - precision: 0.0000\n",
      "1 - recall: 0.0000\n",
      "macro avg - precision: 0.4990\n",
      "macro avg - recall: 0.4999\n",
      "weighted avg - precision: 0.9960\n",
      "weighted avg - recall: 0.9979\n",
      "ROC AUC: 0.9419\n",
      "ROC Curve saved and logged.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/13 13:09:38 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/13 13:09:38 INFO mlflow.tracking._tracking_service.client: üèÉ View run bedecked-bird-385 at: http://127.0.0.1:5000/#/experiments/1/runs/4fb50f5fca84406483e07b8b428175b5.\n",
      "2024/08/13 13:09:38 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved. Default artifacts URI: '/home/maldu/dscience/projects/fraud_detection/experiments/artifacts_local/1/4fb50f5fca84406483e07b8b428175b5/artifacts'\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "        mlflow.set_tag('developer', 'Maldu')\n",
    "\n",
    "        # Crear el modelo base\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluar el modelo en el conjunto de entrenamiento\n",
    "        train_accuracy = model.score(X_train, y_train)\n",
    "        mlflow.log_metric('train_accuracy', train_accuracy)\n",
    "        print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        test_accuracy = model.score(X_test, y_test)\n",
    "        mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "        print(f\"Test Accuracy (using score method): {test_accuracy:.4f}\")\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "        print(\"Confusion Matrix saved and logged.\")\n",
    "\n",
    "        # Classification Report\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Log precision and recall for each class and average\n",
    "        for key, value in report.items():\n",
    "            if isinstance(value, dict):\n",
    "                for sub_key, sub_value in value.items():\n",
    "                    if sub_key in ['precision', 'recall']:\n",
    "                        mlflow.log_param(f'{key}_{sub_key}', sub_value)\n",
    "                        print(f\"{key} - {sub_key}: {sub_value:.4f}\")\n",
    "            else:\n",
    "                if key in ['precision', 'recall']:\n",
    "                    mlflow.log_param(f'{key}', value)\n",
    "                    print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "        # ROC and AUC\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]  # Probabilidades de la clase positiva\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        mlflow.log_metric('roc_auc', roc_auc)\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(\"roc_curve.png\")\n",
    "        mlflow.log_artifact(\"roc_curve.png\")\n",
    "        plt.close()\n",
    "        print(\"ROC Curve saved and logged.\")\n",
    "\n",
    "        # Guardar el modelo\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(f\"Model saved. Default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados y An√°lisis\n",
    "\n",
    "    Precisi√≥n y Recall:\n",
    "        Precisi√≥n (Precision) para la clase 0 es alta, pero para la clase 1 es 0. Esto indica que el modelo no est√° identificando correctamente los ejemplos de la clase 1.\n",
    "        Recall para la clase 0 es muy alto (casi 1), lo que significa que el modelo est√° muy bueno identificando ejemplos de la clase 0.\n",
    "        Recall para la clase 1 es 0, lo que significa que el modelo no est√° identificando ning√∫n ejemplo de la clase 1.\n",
    "\n",
    "    M√©tricas de Evaluaci√≥n:\n",
    "        Precisi√≥n Macro y Recall Macro: Estos valores est√°n alrededor de 0.5, que reflejan el mal desempe√±o en la clase minoritaria.\n",
    "        Precisi√≥n Ponderada y Recall Ponderado: Estos valores son relativamente altos, lo que indica que el modelo se comporta bien en la clase mayoritaria, que puede estar sesgando los resultados debido al desbalance de clases.\n",
    "\n",
    "    ROC AUC:\n",
    "        El AUC de 0.9419 sugiere que el modelo tiene una buena capacidad para distinguir entre las dos clases. Sin embargo, el alto AUC con las m√©tricas de precisi√≥n y recall para la clase 1 en 0 indica que el modelo est√° fallando en la identificaci√≥n de ejemplos positivos, lo que puede ser un signo de desbalance de clases.\n",
    "\n",
    "¬øQu√© Est√° Pasando?\n",
    "\n",
    "El desbalance de clases parece ser el principal problema aqu√≠. La clase 1 (posiblemente la clase de fraude) es mucho menos frecuente en comparaci√≥n con la clase 0, lo que puede estar causando que el modelo se incline hacia la clase mayoritaria.\n",
    "¬øQu√© Puedes Hacer?\n",
    "\n",
    "    Manejo del Desbalance de Clases:\n",
    "        Reescalado de Datos: Usa t√©cnicas como sobremuestreo (SMOTE) para la clase minoritaria o submuestreo de la clase mayoritaria.\n",
    "        Ponderaci√≥n de Clases: Ajusta el par√°metro class_weight en LogisticRegression a 'balanced' para que el modelo preste m√°s atenci√≥n a la clase minoritaria.\n",
    "\n",
    "    Ajuste de Hiperpar√°metros:\n",
    "        Experimenta con diferentes valores de hiperpar√°metros como C, penalty, etc.\n",
    "\n",
    "    Evaluaci√≥n con M√©tricas Adecuadas:\n",
    "        F1 Score: Considera usar el F1 score en lugar de precisi√≥n y recall para obtener una m√©trica que combine ambas.\n",
    "        Matriz de Confusi√≥n: Aseg√∫rate de revisar la matriz de confusi√≥n para entender c√≥mo se est√°n clasificando las diferentes clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection-I9haicwR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
