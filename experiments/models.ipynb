{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import joblib\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import load_npz\n",
    "import joblib\n",
    "import os\n",
    "load_dir = '../../data/gold/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2, Name: fraud_detection_experiment_v1\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment('fraud_detection_experiment_v1')\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name('fraud_detection_experiment_v1')\n",
    "\n",
    "if experiment:\n",
    "    print(f\"ID: {experiment.experiment_id}, Name: {experiment.name}\")\n",
    "else:\n",
    "    print(\"The experiment doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2, Name: fraud_detection_experiment_v1\n",
      "ID: 1, Name: model-experiment-v1\n",
      "ID: 0, Name: Default\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiments = mlflow.search_experiments()\n",
    "    for exp in experiments:\n",
    "        print(f\"ID: {exp.experiment_id}, Name: {exp.name}\")\n",
    "except AttributeError as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = load_npz(os.path.join(load_dir, 'X_train_scaled.npz'))\n",
    "X_test_scaled = load_npz(os.path.join(load_dir, 'X_test_scaled.npz'))\n",
    "\n",
    "# Cargar etiquetas\n",
    "y_train = joblib.load(os.path.join(load_dir, 'y_train.pkl'))\n",
    "y_test = joblib.load(os.path.join(load_dir, 'y_test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'Logistic Regression': {\n",
    "        'C': hp.loguniform('C', -4, 4),\n",
    "        'solver': hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "        'max_iter': hp.quniform('max_iter', 100, 1000, 50),\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': hp.quniform('n_estimators', 10, 200, 10),\n",
    "        'max_depth': hp.quniform('max_depth', 1, 50, 1),\n",
    "        'min_samples_split': hp.uniform('min_samples_split', 0.01, 0.5),\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': hp.quniform('max_depth', 1, 50, 1),\n",
    "        'min_samples_split': hp.uniform('min_samples_split', 0.01, 0.5),\n",
    "    },\n",
    "    'Naive Bayes': {}  # Naive Bayes no tiene hiperparámetros ajustables en este caso\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, model_name):\n",
    "    with mlflow.start_run():\n",
    "        # Inicializa el modelo\n",
    "        if model_name == 'Logistic Regression':\n",
    "            model = LogisticRegression(\n",
    "                C=params['C'],\n",
    "                solver=params['solver'],\n",
    "                max_iter=int(params['max_iter'])\n",
    "            )\n",
    "            # Registrar hiperparámetros\n",
    "            mlflow.log_param('C', params['C'])\n",
    "            mlflow.log_param('solver', params['solver'])\n",
    "            mlflow.log_param('max_iter', int(params['max_iter']))\n",
    "        elif model_name == 'Random Forest':\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=int(params['n_estimators']),\n",
    "                max_depth=int(params['max_depth']),\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                random_state=42\n",
    "            )\n",
    "            # Registrar hiperparámetros\n",
    "            mlflow.log_param('n_estimators', int(params['n_estimators']))\n",
    "            mlflow.log_param('max_depth', int(params['max_depth']))\n",
    "            mlflow.log_param('min_samples_split', params['min_samples_split'])\n",
    "        elif model_name == 'Decision Tree':\n",
    "            model = DecisionTreeClassifier(\n",
    "                max_depth=int(params['max_depth']),\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                random_state=42\n",
    "            )\n",
    "            # Registrar hiperparámetros\n",
    "            mlflow.log_param('max_depth', int(params['max_depth']))\n",
    "            mlflow.log_param('min_samples_split', params['min_samples_split'])\n",
    "        elif model_name == 'Naive Bayes':\n",
    "            model = GaussianNB()\n",
    "            # No hay hiperparámetros para Naive Bayes\n",
    "        else:\n",
    "            raise ValueError(f\"Modelo no soportado: {model_name}\")\n",
    "        \n",
    "        # Entrena el modelo\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evalúa el modelo\n",
    "        accuracy = model.score(X_test_scaled, y_test)\n",
    "        \n",
    "        # Registrar la métrica\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "        \n",
    "        # Guarda el modelo\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        # Retorna la métrica negativa para optimización (Hyperopt minimiza la función objetivo)\n",
    "        return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimización de hiperparámetros para Logistic Regression...\n",
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/07 10:05:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [16:40<13:36:40, 1000.01s/trial, best loss: -0.9991905850105774]"
     ]
    }
   ],
   "source": [
    "for model_name in search_spaces.keys():\n",
    "    print(f\"Optimización de hiperparámetros para {model_name}...\")\n",
    "    \n",
    "    # Crear una nueva instancia de Trials para cada modelo\n",
    "    trials = Trials()\n",
    "    \n",
    "    # Ejecutar la optimización de hiperparámetros\n",
    "    best = fmin(\n",
    "        fn=lambda params: objective(params, model_name),\n",
    "        space=search_spaces[model_name],\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,  # Ajusta el número de evaluaciones según sea necesario\n",
    "        trials=trials\n",
    "    )\n",
    "    \n",
    "    print(f\"Mejores hiperparámetros para {model_name}: {best}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection-I9haicwR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
